{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 02 - Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thông tin sinh viên"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Họ và tên: Nguyễn Thọ Tài\n",
    "- MSSV: 23127255\n",
    "- Lớp: 23CLC02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import các thư viện liên quan"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T03:16:12.289583Z",
     "start_time": "2025-07-27T03:16:05.083578Z"
    }
   },
   "source": [
    "!python -m pip install matplotlib\n",
    "!python -m pip install numpy\n",
    "!python -m pip install Pillow\n",
    "\n",
    "from PIL import Image # for read, write image\n",
    "import numpy as np # for matrix compute\n",
    "import matplotlib.pyplot as plt # for show image\n",
    "import colorsys # for convert RGB to HSL"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: Pillow in d:\\code\\pycharm\\applied_math\\lab03\\.venv\\lib\\site-packages (11.3.0)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T03:41:55.785234Z",
     "start_time": "2025-07-27T03:41:55.765119Z"
    }
   },
   "source": [
    "# Any optional parameters beyond the required ones should be defined with default values\n",
    "def get_base_name(path: str) -> str:\n",
    "\t\"\"\" Get the base name of a file\n",
    "\t\"\"\"\n",
    "\tp = max(path.rfind('/'), path.rfind('\\\\'))\n",
    "\treturn path[p + 1:] if p != -1 else path\n",
    "\n",
    "def get_file_name(path: str) -> str:\n",
    "\tdot = path.rfind('.')\n",
    "\tslash = max(path.rfind('/'), path.rfind('\\\\'))\n",
    "\treturn path[:dot] if dot != -1 and dot > slash else path\n",
    "\n",
    "def get_file_name_without_extension(path: str) -> str:\n",
    "\treturn path.rstrip('/\\\\').split('/')[-1].split('.')[0]\n",
    "\n",
    "def get_folder_path(path: str) -> str:\n",
    "\treturn path[:max(path.rfind('/'), path.rfind('\\\\')) + 1]\n",
    "\n",
    "def get_extension(path: str) -> str:\n",
    "\tp = path.rfind('.')\n",
    "\tif p == -1 or p == 0 or '/' in path[p:]:\n",
    "\t\treturn ''\n",
    "\treturn path[p + 1:]\n",
    "\n",
    "def read_img(img_path) -> np.array:\n",
    "\t\"\"\" Read image from img_path\n",
    "\treturns a 2D image (numpy array) or None if path doesn't exist\n",
    "\t\"\"\"\n",
    "\text = get_extension(img_path)\n",
    "\tif ext not in ['png', 'jpg', 'jpeg']:\n",
    "\t\traise ValueError(f\"Unsupported file extension: '{ext}'\")\n",
    "\traw_img = Image.open(img_path)\n",
    "\tif raw_img is None:\n",
    "\t\treturn ValueError(f\"File '{img_path}' doesn't exist\")\n",
    "\treturn np.array(raw_img.convert('RGB')) #.astype(np.float32)\n",
    "\n",
    "def show_img(img_2d):\n",
    "\t\"\"\" Show image\n",
    "\t\"\"\"\n",
    "\tplt.imshow(img_2d.astype(np.uint8))\n",
    "\tplt.axis('off')\n",
    "\tplt.show()\n",
    "\n",
    "def save_img(img_2d, img_path: str):\n",
    "\t\"\"\"\tSave image to img_path\n",
    "\t\"\"\"\n",
    "\text = get_extension(img_path)\n",
    "\tif ext not in ['png', 'jpg', 'jpeg']:\n",
    "\t\traise ValueError(f\"Unsupported file extension: '{ext}'\")\n",
    "\tif img_2d.dtype != np.uint8:\n",
    "\t\timg_2d = img_2d.astype(np.uint8) # casting the arr to uint8 if they ain't\n",
    "\tImage.fromarray(img_2d).save(img_path) # exception: OSError\n",
    "\n",
    "def convert_rgb_to_hsl(img_2d: np.array) -> np.array:\n",
    "\t\"\"\" Convert RGB image to HSL image\n",
    "\treturns a 2D image (numpy array)\n",
    "\t\"\"\"\n",
    "\tnorm_img = img_2d / 255.0\n",
    "\trgb2hsl_vec = np.vectorize(colorsys.rgb_to_hls)\n",
    "\th, l, s = rgb2hsl_vec(norm_img[..., 0], norm_img[..., 1], norm_img[..., 2]) # img[..., 0] means take all previous dim but only the 0 index of the last one. (4, 4, 3) -> (4, 3)\n",
    "\treturn np.dstack([h, s, l]) # hsl\n",
    "\n",
    "def convert_hsl_to_rgb(img_2d: np.array) -> np.array:\n",
    "\t\"\"\" Convert HSL image to RGB image\n",
    "\treturns a 2D image (numpy array)\n",
    "\t\"\"\"\n",
    "\thsl2rgb_vec = np.vectorize(colorsys.hls_to_rgb)\n",
    "\tr, g, b = hsl2rgb_vec(img_2d[..., 0], img_2d[..., 1], img_2d[..., 2])\n",
    "\tif img_2d.ndim == 4:\n",
    "\t\treturn np.dstack([r, g, b, img_2d[..., 3]] * 255).astype(np.uint8) # rgba\n",
    "\treturn (np.dstack([r, g, b]) * 255).astype(np.uint8) # rgb\n",
    "\n",
    "# 1. Change the image brightness\n",
    "def img_change_brightness(img_2d: np.array, value: int) -> np.array:\n",
    "\timg_2d = img_2d.astype(np.float32)\n",
    "\timg_2d += value\n",
    "\treturn np.clip(img_2d, 0, 255).astype(np.uint8)\n",
    "\n",
    "# 2. Change the image contrast\n",
    "def img_change_contrast(img_2d: np.array, factor: float) -> np.array:\n",
    "\timg_2d = img_2d.astype(np.float32)\n",
    "\timg_2d -= 127.0  # map the range from (0,256) to (-127, 128) with dark parts being lower than 0 and the opposite for light part\n",
    "\timg_2d *= factor # distance the dark and light part by factor amount\n",
    "\timg_2d += 127.0  # remap it back to normal range (0, 256)\n",
    "\tnp.clip(img_2d, 0, 255, out=img_2d) # clip out overflowed value\n",
    "\treturn img_2d.astype(np.uint8)\n",
    "\n",
    "\"\"\"\n",
    "Convert to grayscale (rec601, rec709)\n",
    "\n",
    "Ref:\n",
    "- Wikipedia, Rec.601 luma versus Rec.709 luma coefficients,\n",
    "Accessed 17 July 2025, https://en.wikipedia.org/wiki/Luma_(video)#Rec._601_luma_versus_Rec._709_luma_coefficients\n",
    "- OpenCV, CvtColor - Miscellaneous transformations\n",
    "Accessed 20 July 2025, https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor\n",
    "\"\"\"\n",
    "# 4. RGB to grayscale\n",
    "def img_to_grayscale(img_2d: np.array, mode: str = 'rec709') -> np.array:\n",
    "\tif mode == 'rec709':\n",
    "\t\t# rec709: l = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "\t\tluma = 0.2126 * img_2d[:, :, 0] + 0.7152 * img_2d[:, :, 1] + 0.0722 * img_2d[:, :, 2]\n",
    "\telif mode == 'rec601':\n",
    "\t\t# rec601: l = 0.2989 * r + 0.587 * g + 0.114 * b\n",
    "\t\tluma = 0.2989 * img_2d[:, :, 0] + 0.587 * img_2d[:, :, 1] + 0.114 * img_2d[:, :, 2]\n",
    "\telse:\n",
    "\t\treturn img_2d # return raw image\n",
    "\tresult = np.zeros_like(img_2d, dtype=np.uint8) # initialize an empty result array\n",
    "\tresult[:, :, 0] = result[:, :, 1] = result[:, :, 2] = luma\n",
    "\treturn result\n",
    "\n",
    "# def img_to_grayscale_direct(img_2d: np.array, mode: str = 'rec709'):\n",
    "# \tif mode == 'rec709':\n",
    "# \t\t# rec709: l = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "# \t\tluma = 0.2126 * img_2d[:, :, 0] + 0.7152 * img_2d[:, :, 1] + 0.0722 * img_2d[:, :, 2]\n",
    "# \telif mode == 'rec601':\n",
    "# \t\t# rec601: l = 0.2989 * r + 0.587 * g + 0.114 * b\n",
    "# \t\tluma = 0.2989 * img_2d[:, :, 0] + 0.587 * img_2d[:, :, 1] + 0.114 * img_2d[:, :, 2]\n",
    "# \telse:\n",
    "# \t\treturn\n",
    "# \timg_2d[:, :, 0] = img_2d[:, :, 1] = img_2d[:, :, 2] = luma\n",
    "\n",
    "\"\"\"\n",
    "Applies a sepia effect.\n",
    "\n",
    "Ref:\n",
    "- Stack Overflow, Processing an image to sepia tone in Python\n",
    "Accessed 24 July 2025, https://stackoverflow.com/q/36434905\n",
    "\"\"\"\n",
    "# 4. RGB to sepia tone\n",
    "def img_to_sepia(img_2d: np.array) -> np.array:\n",
    "\timg_2d = img_2d.astype(np.float32)\n",
    "\tsepia_filter = np.array([\n",
    "\t\t[0.393, 0.769, 0.189],\n",
    "\t\t[0.349, 0.686, 0.168],\n",
    "\t\t[0.272, 0.534, 0.131]\n",
    "\t], dtype=np.float32)\n",
    "\t# apply the sepia filter to each pixel using matrix mul\n",
    "\timg_2d = np.clip(np.dot(img_2d, sepia_filter.T), 0, 255)\n",
    "\treturn img_2d.astype(np.uint8)\n",
    "\n",
    "def img_flip_horizontal(img_2d: np.array) -> np.array:\n",
    "\treturn img_2d[:, ::-1]\n",
    "\n",
    "def img_flip_vertical(img_2d: np.array) -> np.array:\n",
    "\treturn img_2d[::-1, :]\n",
    "\n",
    "def img_flip_horizontal_vertical(img_2d: np.array) -> np.array:\n",
    "\treturn img_2d[::-1, ::-1]\n",
    "\n",
    "# 3. Image flip\n",
    "def img_flip(img_2d: np.array, mode: str ='horizontal') -> np.array:\n",
    "\tif mode == 'horizontal':\n",
    "\t\treturn img_flip_horizontal(img_2d)\n",
    "\tif mode == 'vertical':\n",
    "\t\treturn img_flip_vertical(img_2d)\n",
    "\tif mode == 'both':\n",
    "\t\treturn img_flip_horizontal_vertical(img_2d)\n",
    "\treturn img_2d\n",
    "\n",
    "def img_crop(img_2d: np.array, start: list[int], end: list[int]) -> np.array:\n",
    "\theight, width, _ = img_2d.shape\n",
    "\tx1, x2 = sorted([max(0, min(start[0], width)), max(0, min(end[0], width))])\n",
    "\ty1, y2 = sorted([max(0, min(start[1], height)), max(0, min(end[1], height))])\n",
    "\treturn img_2d[y1:y2, x1:x2, :].astype(np.uint8)\n",
    "\n",
    "# 6. Crop a quarter at the center of the image\n",
    "def img_crop_quarter_center(img_2d: np.array) -> np.array:\n",
    "\theight, width, _ = img_2d.shape\n",
    "\tstart_height, start_width = height // 4, width // 4\n",
    "\treturn img_crop(img_2d, [start_width, start_height], [start_width * 3, start_height * 3])\n",
    "\n",
    "\"\"\"\n",
    "Using np.ogrid to mask the image\n",
    "\n",
    "Ref:\n",
    "https://medium.com/data-science/the-little-known-ogrid-function-in-numpy-19ead3bdae40\n",
    "\"\"\"\n",
    "def img_circle_mask(img_2d: np.array) -> np.array:\n",
    "\tmasked_img = img_2d.copy()\n",
    "\theight, width, _ = img_2d.shape\n",
    "\ty, x = np.ogrid[:height, :width]\n",
    "\tcy, cx = height // 2, width // 2\n",
    "\tr = min(cx, cy)\n",
    "\tmask = (x - cx) ** 2 + (y - cy) ** 2 <= r ** 2\n",
    "\tmasked_img[~mask] = np.zeros((height, width, 3), np.uint8)[~mask]\n",
    "\treturn masked_img\n",
    "\n",
    "def img_circle_mask(img_2d: np.array) -> np.array:\n",
    "\th, w, _ = img_2d.shape\n",
    "\tcy, cx = h // 2, w // 2\n",
    "\tr = min(cx, cy)\n",
    "\ty, x = np.ogrid[:h, :w]\n",
    "\tmask = (x - cx) ** 2 + (y - cy) ** 2 <= r ** 2\n",
    "\tmasked_img = np.zeros_like(img_2d)\n",
    "\tmasked_img[mask] = img_2d[mask]\n",
    "\treturn masked_img\n",
    "\n",
    "def rotated_ellipse_mask(x, y, a, b, theta):\n",
    "\tcos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "\tterm1 = ((x * cos_t + y * sin_t) ** 2) / a ** 2\n",
    "\tterm2 = ((x * sin_t - y * cos_t) ** 2) / b ** 2\n",
    "\treturn (term1 + term2) <= 1 # x^2 / a^2 + y^2 / b^2 <= 1, take the inner part\n",
    "\n",
    "def img_2ellipse_mask(img_2d: np.ndarray) -> np.array:\n",
    "\tmasked_img = img_2d.copy()\n",
    "\theight, width, _ = img_2d.shape\n",
    "\tdiag = 1.4142 * min(height, width) - 5\n",
    "\t# a = (7 / 8) * diag / 2, b = 0.5 * diag / 2\n",
    "\ta, b = 0.4375 * diag, 0.25 * diag\n",
    "\ttheta = np.pi / 4\n",
    "\ty, x = np.ogrid[:height, :width]\n",
    "\t# translate the grid coord to the center of the shape\n",
    "\ty -= height // 2\n",
    "\tx -= width // 2\n",
    "\n",
    "\tmask = np.logical_or(rotated_ellipse_mask(x, y, a, b, theta), rotated_ellipse_mask(x, y, a, b, -theta))\n",
    "\tmasked_img[mask] = np.zeros_like(img_2d)[mask]\n",
    "\treturn masked_img\n",
    "\n",
    "# 7. Crop image by frame\n",
    "def img_mask(img_2d: np.array, mode: str = 'circle') -> np.array:\n",
    "\t\"\"\"\n",
    "\n",
    "\t\"\"\"\n",
    "\tif mode == 'circle':\n",
    "\t\treturn img_circle_mask(img_2d)\n",
    "\tif mode == 'ellipse':\n",
    "\t\treturn img_2ellipse_mask(img_2d)\n",
    "\treturn img_2d\n",
    "\n",
    "def kernel_identity(size: int) -> np.array:\n",
    "\treturn np.pad([[1]], pad_width=size//2)\n",
    "\n",
    "def kernel_box_blur(size: int) -> np.ndarray:\n",
    "\treturn np.ones((size, size)) / size ** 2\n",
    "\n",
    "def kernel_gauss_blur(size: int) -> np.ndarray:\n",
    "\tif size % 2 == 0 or size < 1:\n",
    "\t\traise ValueError(\"Size must be odd and positive\")\n",
    "\tkernel_1d = np.array([1, 1])\n",
    "\tfor _ in range(size - 2):\n",
    "\t\tkernel_1d = np.convolve(kernel_1d, [1, 1])\n",
    "\treturn np.outer(kernel_1d, kernel_1d) / (4 ** (size - 1))\n",
    "\n",
    "MAT_BOX_BLUR_3 = kernel_box_blur(3)\n",
    "MAT_BOX_BLUR_5 = kernel_box_blur(5)\n",
    "MAT_BOX_BLUR_7 = kernel_box_blur(7)\n",
    "MAT_BOX_BLUR_15 = kernel_box_blur(15)\n",
    "\n",
    "MAT_GAUSS_BLUR_3 = 0.0625 * np.array(\n",
    "\t[[1, 2, 1],\n",
    "\t [2, 4, 2],\n",
    "\t [1, 2, 1]])\n",
    "\n",
    "MAT_GAUSS_BLUR_5 = 0.00390625 * np.array(\n",
    "\t[[1,  4,  6,  4,  1],\n",
    "\t [4, 16, 24, 16, 14],\n",
    "\t [6, 24, 36, 24,  6],\n",
    "\t [4, 16, 24, 16,  4],\n",
    "\t [1,  4,  6,  4,  1]])\n",
    "\n",
    "MAT_GAUSS_BLUR_7 = kernel_gauss_blur(7)\n",
    "MAT_GAUSS_BLUR_15 = kernel_gauss_blur(15)\n",
    "MAT_GAUSS_BLUR_21 = kernel_gauss_blur(21)\n",
    "\n",
    "MAT_UNSHARP_BLUR_5 = -0.00390625 * np.array(\n",
    "\t[[1,  4,    6,  4,  1],\n",
    "\t [4, 16,   24, 16, 14],\n",
    "\t [6, 24, -476, 24,  6],\n",
    "\t [4, 16,   24, 16,  4],\n",
    "\t [1,  4,    6,  4,  1]])\n",
    "\n",
    "def kernel_convolution(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float16) / 255.0\n",
    "\theight, width, _ = norm_img.shape\n",
    "\tk_height, k_width = kernel.shape\n",
    "\tif k_height != k_width:\n",
    "\t\traise ValueError('Input kernel matrix must be square')\n",
    "\n",
    "\t# pad image to handle boundaries\n",
    "\tpad_size = k_height // 2\n",
    "\tpad_img = np.pad(norm_img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant')\n",
    "\n",
    "\tpatches = np.lib.stride_tricks.sliding_window_view(pad_img, window_shape=(k_height, k_height), axis=(0, 1)) # shape: (height, width, channel, k_height, k_width)\n",
    "\tresult = np.einsum('abcde,de->abc', patches, kernel)\n",
    "\tresult = np.clip(result * 255, 0, 255).astype(np.uint8)\n",
    "\treturn result\n",
    "\n",
    "# 5. Blur and sharpen the image\n",
    "def img_blur_sharpen(img_2d: np.ndarray, mode: str = \"blur\") -> np.ndarray:\n",
    "\tif mode == \"blur\":\n",
    "\t\treturn kernel_convolution(img_2d, MAT_GAUSS_BLUR_5)\n",
    "\tif mode == \"sharpen\":\n",
    "\t\treturn kernel_convolution(img_2d, MAT_UNSHARP_BLUR_5)\n",
    "\treturn img_2d\n",
    "\n",
    "def process_image(img_2d, func=[1, 2, 3,...]):\n",
    "\t\"\"\" Process image with a list of functions\n",
    "\tfunc: a list of functions to apply to the image\n",
    "\treturn processed 2D image\n",
    "\t\"\"\"\n",
    "\t# for f in func:\n",
    "\t# \tmatch f:\n",
    "\t# \t\tcase 1: return\n",
    "\t# \t\tcase _: return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T04:31:01.625621Z",
     "start_time": "2025-07-27T04:31:01.525876Z"
    }
   },
   "source": [
    "import os\n",
    "import tracemalloc\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def test_flip():\n",
    "\tfolder = \"image/flip/\"\n",
    "\tos.makedirs(\"image/flip/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tflip_h_img = img_flip_horizontal(img)\n",
    "\tflip_v_img = img_flip_vertical(img)\n",
    "\tflip_hv_img = img_flip_horizontal_vertical(img)\n",
    "\tsave_img(flip_h_img, \"image/flip/flip_horizontal_cat.jpg\")\n",
    "\tsave_img(flip_v_img, \"image/flip/flip_vertical_cat.jpg\")\n",
    "\tsave_img(flip_hv_img, \"image/flip/flip_horizontal_vertical_cat.jpg\")\n",
    "\n",
    "def test_mask(file_path: str):\n",
    "\tos.makedirs(\"image/mask/\", exist_ok=True)\n",
    "\timg = read_img(file_path)\n",
    "\tprint(img.dtype, img.shape)\n",
    "\tfile_name_no_ext = get_file_name_without_extension(file_path)\n",
    "\tcircle_masked_img = img_circle_mask(img)\n",
    "\tellipse_masked_img = img_2ellipse_mask(img)\n",
    "\tget_base_name(file_path)\n",
    "\tsave_img(circle_masked_img, f\"image/mask/mask_circle_{file_name_no_ext}.jpg\")\n",
    "\tsave_img(ellipse_masked_img, f\"image/mask/mask_ellipse_{file_name_no_ext}.jpg\")\n",
    "\n",
    "def test_color_filter(file_path: str):\n",
    "\tfolder = \"image/color_filter/\"\n",
    "\tos.makedirs(folder, exist_ok=True)\n",
    "\timg = read_img(file_path)\n",
    "\tfile_name_no_ext = get_file_name_without_extension(file_path)\n",
    "\tgray_709_img = img_to_grayscale(img, 'rec709')\n",
    "\tgray_601_img = img_to_grayscale(img, 'rec601')\n",
    "\tsepia_img = img_to_sepia(img)\n",
    "\tsave_img(gray_601_img, folder + f\"grayscale_r601_{file_name_no_ext}.jpg\")\n",
    "\tsave_img(gray_709_img, folder + f\"grayscale_r709_{file_name_no_ext}.jpg\")\n",
    "\tsave_img(sepia_img, folder + f\"sepia_{file_name_no_ext}.jpg\")\n",
    "\n",
    "def test_brightness_contrast(file_path: str, value: int = 50, factor: float = 1.5):\n",
    "\tfolder = \"image/brightness_contrast/\"\n",
    "\tos.makedirs(folder, exist_ok=True)\n",
    "\timg = read_img(file_path)\n",
    "\tfile_name_no_ext = get_file_name_without_extension(file_path)\n",
    "\tbrightness_img = img_change_brightness(img, value)\n",
    "\tcontrast_img = img_change_contrast(img, factor)\n",
    "\tsave_img(brightness_img, folder + f\"brightness_{value}_{file_name_no_ext}.jpg\")\n",
    "\tsave_img(contrast_img, folder + f\"contrast_{factor}_{file_name_no_ext}.jpg\")\n",
    "\n",
    "def test_crop_image(file_path: str):\n",
    "\tfolder = \"image/crop_image/\"\n",
    "\tos.makedirs(folder, exist_ok=True)\n",
    "\timg = read_img(file_path)\n",
    "\tfile_name_no_ext = get_file_name_without_extension(file_path)\n",
    "\tcrop_img = img_crop_quarter_center(img)\n",
    "\tsave_img(crop_img, folder + f\"crop_{file_name_no_ext}.jpg\")\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "def file_stdout(file: str):\n",
    "\tsys.stdout = open(file, 'w')\n",
    "\n",
    "def reset_stdout():\n",
    "\tsys.stdout.close()\n",
    "\tsys.stdout = orig_stdout\n",
    "\n",
    "test_mask('cat.jpg')\n",
    "# test_color_filter('cat.jpg')\n",
    "# test_flip()\n",
    "# test_brightness_contrast('cat.jpg', -50, 0.5)\n",
    "# test_crop_image('cat.jpg')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 (800, 800, 3)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T04:31:04.860697Z",
     "start_time": "2025-07-27T04:31:03.529119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_kernel_convolution_raw():\n",
    "\timg = np.array([\n",
    "\t\t[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "\t\t[[10, 11, 12], [13, 14, 15], [16, 17, 18]],\n",
    "\t\t[[19, 20, 21], [22, 23, 24], [25, 26, 27]]\n",
    "\t], dtype=np.uint8)\n",
    "\n",
    "\tkernel_3x3 = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=np.float32)\n",
    "\tresult_3x3 = kernel_convolution(img, kernel_3x3)\n",
    "\tprint(f\"Result: \\n{result_3x3}\\n\")\n",
    "\n",
    "def benchmark_kernel_convolution(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = kernel_convolution(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution():\n",
    "\tos.makedirs(\"image/kernel/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\t# box_blur_3_img = benchmark_kernel_convolution('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\t# box_blur_7_img = benchmark_kernel_convolution('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\t# box_blur_15_img = benchmark_kernel_convolution('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\t# gauss_blur_3_img = benchmark_kernel_convolution('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\t# gauss_blur_7_img = benchmark_kernel_convolution('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\t# gauss_blur_15_img = benchmark_kernel_convolution('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\t# gauss_blur_21_img = benchmark_kernel_convolution('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\t# save_img(box_blur_3_img, \"image/kernel/box_blur_3_cat.png\")\n",
    "\t# save_img(box_blur_7_img, \"image/kernel/box_blur_7_cat.png\")\n",
    "\t# save_img(box_blur_15_img, \"image/kernel/box_blur_15_cat.png\")\n",
    "\n",
    "\t# save_img(gauss_blur_3_img, \"image/kernel/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel/gauss_blur_5_cat.jpg\")\n",
    "\t# save_img(gauss_blur_7_img, \"image/kernel/gauss_blur_7_cat.png\")\n",
    "\t# save_img(gauss_blur_15_img, \"image/kernel/gauss_blur_15_cat.png\")\n",
    "\t# save_img(gauss_blur_21_img, \"image/kernel/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel/unsharp_blur_cat.jpg\")\n",
    "file_stdout(\"output/bench_normal.txt\")\n",
    "test_kernel_convolution()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main FUNCTION"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T04:07:36.306604Z",
     "start_time": "2025-07-27T04:06:41.354101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_help():\n",
    "\tprint(\"Please select of of the following functionality\\n\"\n",
    "\t\"0. Save image\\n\"\n",
    "\t\"1. Adjust brightness\\n\"\n",
    "\t\"2. Adjust contrast\\n\"\n",
    "\t\"3. Flip image horizontally/vertically\\n\"\n",
    "\t\"4. Convert image to grayscale/sepia\\n\"\n",
    "\t\"5. Blur/sharpen image\\n\"\n",
    "\t\"6. Cut quarter image at the center\\n\"\n",
    "\t\"7. Cut image with circle/ellipse frame\\n\")\n",
    "\n",
    "def main():\n",
    "\t# print(\"Path to the image: \")\n",
    "\timg_path = str(input(\"Path to the image: \"))\n",
    "\n",
    "\ttry:\n",
    "\t\timg = read_img(img_path)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\treturn\n",
    "\n",
    "\tfile_name_no_ext = get_file_name_without_extension(img_path)\n",
    "\tprint_help()\n",
    "\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tchoice = int(input(\"Enter the number corresponding to your choice: \"))\n",
    "\t\t\tif choice == 0:\n",
    "\t\t\t\t# Apply all transformations\n",
    "\t\t\t\timg = img_change_brightness(img, 50)\n",
    "\t\t\t\timg = img_change_contrast(img, 1.5)\n",
    "\t\t\t\timg = img_flip(img, mode=\"both\")\n",
    "\t\t\t\timg = img_to_grayscale(img)\n",
    "\t\t\t\timg = img_to_sepia(img)\n",
    "\t\t\t\timg = img_blur_sharpen(img, mode=\"blur\")\n",
    "\t\t\t\timg = img_crop_quarter_center(img)\n",
    "\t\t\t\timg = img_mask(img, mode=\"ellipse\")\n",
    "\t\t\t\tprint(\"All transformations applied.\")\n",
    "\t\t\telif choice == 1:\n",
    "\t\t\t\t# Adjust brightness\n",
    "\t\t\t\tvalue = int(input(\"Enter brightness value (positive or negative): \"))\n",
    "\t\t\t\timg = img_change_brightness(img, value)\n",
    "\t\t\t\tprint(\"Brightness adjusted.\")\n",
    "\t\t\telif choice == 2:\n",
    "\t\t\t\t# Adjust contrast\n",
    "\t\t\t\tfactor = float(input(\"Enter contrast factor (e.g., 1.5): \"))\n",
    "\t\t\t\timg = img_change_contrast(img, factor)\n",
    "\t\t\t\tprint(\"Contrast adjusted.\")\n",
    "\t\t\telif choice == 3:\n",
    "\t\t\t\t# Flip image\n",
    "\t\t\t\tflip_mode = input(\"Enter flip mode (horizontal/vertical/both): \")\n",
    "\t\t\t\timg = img_flip(img, mode=flip_mode)\n",
    "\t\t\t\tprint(f\"Image flipped {flip_mode}.\")\n",
    "\t\t\telif choice == 4:\n",
    "\t\t\t\t# Convert image to grayscale or sepia\n",
    "\t\t\t\tcolor_mode = input(\"Enter mode (grayscale/sepia): \")\n",
    "\t\t\t\tif color_mode == 'grayscale':\n",
    "\t\t\t\t\tmode = input(\"Enter grayscale mode (rec601/rec709): \")\n",
    "\t\t\t\t\timg = img_to_grayscale(img, mode=mode)\n",
    "\t\t\t\t\tprint(\"Image converted to grayscale.\")\n",
    "\t\t\t\telif color_mode == 'sepia':\n",
    "\t\t\t\t\timg = img_to_sepia(img)\n",
    "\t\t\t\t\tprint(\"Image converted to sepia.\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"Invalid mode. Skipping conversion.\")\n",
    "\t\t\telif choice == 5:\n",
    "\t\t\t\t# Blur or sharpen image\n",
    "\t\t\t\tblur_sharpen_mode = input(\"Enter mode (blur/sharpen): \")\n",
    "\t\t\t\timg = img_blur_sharpen(img, mode=blur_sharpen_mode)\n",
    "\t\t\t\tprint(f\"Image {blur_sharpen_mode} applied.\")\n",
    "\t\t\telif choice == 6:\n",
    "\t\t\t\t# Cut quarter image at the center\n",
    "\t\t\t\timg = img_crop_quarter_center(img)\n",
    "\t\t\t\tprint(\"Quarter of the image at the center cropped.\")\n",
    "\t\t\telif choice == 7:\n",
    "\t\t\t\t# Cut image with circle/ellipse frame\n",
    "\t\t\t\tframe_mode = input(\"Enter frame mode (circle/ellipse): \")\n",
    "\t\t\t\timg = img_mask(img, mode=frame_mode)\n",
    "\t\t\t\tprint(f\"Image masked with {frame_mode} frame.\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"Invalid option. Please try again.\")\n",
    "\n",
    "\t\t\t# Ask if user wants to continue\n",
    "\t\t\tcontinue_choice = input(\"Do you want to apply more transformations? (yes/no): \").strip().lower()\n",
    "\t\t\tif continue_choice != 'yes':\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\texcept ValueError:\n",
    "\t\t\tprint(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "\t# Ask for saving the image\n",
    "\tsave_choice = input(\"Do you want to save the modified image? (yes/no): \").strip().lower()\n",
    "\tif save_choice == 'yes':\n",
    "\t\toutput_path = input(\"Enter the output file path (including extension): \")\n",
    "\t\ttry:\n",
    "\t\t\tsave_img(img, output_path)\n",
    "\t\t\tprint(f\"Image saved to {output_path}\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error saving image: {e}\")\n",
    "\n",
    "\tprint(\"Process finished.\")\n",
    "\n",
    "main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select of of the following functionality\n",
      "0. Save image\n",
      "1. Adjust brightness\n",
      "2. Adjust contrast\n",
      "3. Flip image horizontally/vertically\n",
      "4. Convert image to grayscale/sepia\n",
      "5. Blur/sharpen image\n",
      "6. Cut quarter image at the center\n",
      "7. Cut image with circle/ellipse frame\n",
      "\n",
      "Invalid input. Please enter a valid number.\n",
      "Brightness adjusted.\n",
      "Contrast adjusted.\n",
      "Image saved to out.png\n",
      "Process finished.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tile 1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tiled_kernel_convolution_t1(img_2d: np.ndarray, kernel: np.ndarray, tile_size: int = 256) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\tif kernel.shape[0] != kernel.shape[1]:\n",
    "\t\traise ValueError('Input kernel matrix must be square')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0  # stick with float32 for accuracy\n",
    "\theight, width, channels = norm_img.shape\n",
    "\n",
    "\tk_height = kernel.shape[0]\n",
    "\tpad_size = k_height // 2\n",
    "\tpad_img = np.pad(norm_img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant')\n",
    "\tresult = np.zeros_like(norm_img)\n",
    "\tpad_tile_size = tile_size + 2 * pad_size\n",
    "\t# com_kernel = kernel[None, None, None, :, :]\n",
    "\tfor i in range(0, height, tile_size):\n",
    "\t\tfor j in range(0, width, tile_size):\n",
    "\t\t\ti_end = min(i + pad_tile_size, pad_img.shape[0])\n",
    "\t\t\tj_end = min(j + pad_tile_size, pad_img.shape[1])\n",
    "\t\t\ttile = pad_img[i:i_end, j:j_end]\n",
    "\t\t\t# noinspection PyTypeChecker\n",
    "\t\t\ttile_patches = np.lib.stride_tricks.sliding_window_view(tile, window_shape=(k_height, k_height), axis=(0, 1))\n",
    "\t\t\t# tile_result = np.sum(tile_patches * com_kernel, axis=(3, 4))\n",
    "\t\t\t# Rewrite of the above hadamard product of tile_patches and kernel using einsum: https://stackoverflow.com/a/33641428\n",
    "\t\t\t# This help with performance and don't create a temp large ndarray causing bottleneck\n",
    "\t\t\ttile_result = np.einsum('abcde,de->abc', tile_patches, kernel)\n",
    "\t\t\tresult[i:min(i + tile_size, height), j:min(j + tile_size, width)] = tile_result[:min(tile_size, height - i), :min(tile_size, width - j)]\n",
    "\n",
    "\treturn np.clip(result * 255, 0, 255).astype(np.uint8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_kernel_convolution_t1(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = tiled_kernel_convolution_t1(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution_t1():\n",
    "\tos.makedirs(\"image/kernel_t1/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_kernel_convolution_t1('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_kernel_convolution_t1('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_kernel_convolution_t1('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_kernel_convolution_t1('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution_t1('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_kernel_convolution_t1('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_kernel_convolution_t1('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_kernel_convolution_t1('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution_t1('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/kernel_t1/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/kernel_t1/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/kernel_t1/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/kernel_t1/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel_t1/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/kernel_t1/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/kernel_t1/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/kernel_t1/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel_t1/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_tiled_t1_256.txt\")\n",
    "test_kernel_convolution_t1()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_kernel_convolution_t1_512(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = tiled_kernel_convolution_t1(img_2d, kernel, 512)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution_t1_512():\n",
    "\tos.makedirs(\"image/kernel_t1_512/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_kernel_convolution_t1_512('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_kernel_convolution_t1_512('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_kernel_convolution_t1_512('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_kernel_convolution_t1_512('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution_t1_512('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_kernel_convolution_t1_512('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_kernel_convolution_t1_512('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_kernel_convolution_t1_512('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution_t1_512('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/kernel_t1_512/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/kernel_t1_512/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/kernel_t1_512/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/kernel_t1_512/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel_t1_512/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/kernel_t1_512/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/kernel_t1_512/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/kernel_t1_512/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel_t1_512/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_tiled_t1_512.txt\")\n",
    "test_kernel_convolution_t1_512()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tile 2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tiled_kernel_convolution_t2(img_2d: np.ndarray, kernel: np.ndarray, tile_size: int = 256) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\tif kernel.shape[0] != kernel.shape[1]:\n",
    "\t\traise ValueError('Input kernel matrix must be square')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\theight, width, channels = norm_img.shape\n",
    "\tk_height = kernel.shape[0]\n",
    "\tpad_size = k_height // 2\n",
    "\tpad_img = np.pad(norm_img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant')\n",
    "\n",
    "\ttile_shape = (tile_size + 2 * pad_size, tile_size + 2 * pad_size)\n",
    "\ttiles = np.lib.stride_tricks.sliding_window_view(pad_img, window_shape=tile_shape, axis=(0, 1))\n",
    "\ttiles = tiles[::tile_size, ::tile_size].reshape(-1, tile_shape[0], tile_shape[1], channels)\n",
    "\n",
    "\tresult = np.zeros_like(norm_img)\n",
    "\t# com_kernel = kernel[None, None, None, :, :]\n",
    "\tfor idx, tile in enumerate(tiles):\n",
    "\t\ti = (idx // (width // tile_size)) * tile_size\n",
    "\t\tj = (idx % (width // tile_size)) * tile_size\n",
    "\t\tif i >= height or j >= width:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\ttile_patches = np.lib.stride_tricks.sliding_window_view(tile, window_shape=(k_height, k_height), axis=(0, 1))\n",
    "\t\t# tile_result = np.sum(tile_patches * com_kernel, axis=(3, 4))\n",
    "\t\ttile_result = np.einsum('abcde,de->abc', tile_patches, kernel)\n",
    "\n",
    "\t\tresult_i_end = min(i + tile_size, height)\n",
    "\t\tresult_j_end = min(j + tile_size, width)\n",
    "\t\ttile_i_end = min(tile_size, height - i)\n",
    "\t\ttile_j_end = min(tile_size, width - j)\n",
    "\t\tresult[i:result_i_end, j:result_j_end] = tile_result[:tile_i_end, :tile_j_end]\n",
    "\n",
    "\treturn np.clip(result * 255, 0, 255).astype(np.uint8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_kernel_convolution_t2(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = tiled_kernel_convolution_t2(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution_t2():\n",
    "\tos.makedirs(\"image/kernel_t2/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_kernel_convolution_t2('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_kernel_convolution_t2('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_kernel_convolution_t2('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_kernel_convolution_t2('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution_t2('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_kernel_convolution_t2('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_kernel_convolution_t2('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_kernel_convolution_t2('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution_t2('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/kernel_t2/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/kernel_t2/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/kernel_t2/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/kernel_t2/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel_t2/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/kernel_t2/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/kernel_t2/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/kernel_t2/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel_t2/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_tiled_t2_256.txt\")\n",
    "test_kernel_convolution_t2()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_kernel_convolution_t2_512(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = tiled_kernel_convolution_t2(img_2d, kernel, 512)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution_t2_512():\n",
    "\tos.makedirs(\"image/kernel_t2_512/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_kernel_convolution_t2_512('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_kernel_convolution_t2_512('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_kernel_convolution_t2_512('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_kernel_convolution_t2_512('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution_t2_512('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_kernel_convolution_t2_512('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_kernel_convolution_t2_512('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_kernel_convolution_t2_512('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution_t2_512('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/kernel_t2_512/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/kernel_t2_512/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/kernel_t2_512/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/kernel_t2_512/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel_t2_512/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/kernel_t2_512/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/kernel_t2_512/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/kernel_t2_512/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel_t2_512/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_tiled_t2_512.txt\")\n",
    "test_kernel_convolution_t2_512()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tile 3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tiled_kernel_convolution_t3(img_2d: np.ndarray, kernel: np.ndarray, tile_size: int = 256) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\tif kernel.shape[0] != kernel.shape[1]:\n",
    "\t\traise ValueError('Input kernel matrix must be square')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\theight, width, channels = norm_img.shape\n",
    "\tk_height = kernel.shape[0]\n",
    "\tpad_size = k_height // 2\n",
    "\tpad_img = np.pad(norm_img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant')\n",
    "\tresult = np.zeros((height, width, channels), dtype=np.float32)\n",
    "\n",
    "\ttile_pad_size = tile_size + 2 * pad_size\n",
    "\n",
    "\tfor i in range(0, height, tile_size):\n",
    "\t\tfor j in range(0, width, tile_size):\n",
    "\t\t\ttmp = tile_pad_size\n",
    "\t\t\ti_end = min(i + tmp, pad_img.shape[0])\n",
    "\t\t\tj_end = min(j + tmp, pad_img.shape[1])\n",
    "\t\t\ttile = pad_img[i:i_end, j:j_end]\n",
    "\t\t\ttile_patches = np.lib.stride_tricks.sliding_window_view(tile, window_shape=(k_height, k_height), axis=(0, 1))\n",
    "\t\t\ttile_result = np.einsum('abcde,de->abc', tile_patches, kernel)\n",
    "\t\t\tresult[i:min(i + tile_size, height), j:min(j + tile_size, width)] = tile_result[:min(tile_size, height - i), :min(tile_size, width - j)]\n",
    "\n",
    "\treturn np.clip(result * 255, 0, 255).astype(np.uint8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_kernel_convolution_t3(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = tiled_kernel_convolution_t3(img_2d, kernel, 256)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_kernel_convolution_t3():\n",
    "\tos.makedirs(\"image/fft/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_kernel_convolution_t3('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_kernel_convolution_t3('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_kernel_convolution_t3('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_kernel_convolution_t3('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_kernel_convolution_t3('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_kernel_convolution_t3('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_kernel_convolution_t3('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_kernel_convolution_t3('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_kernel_convolution_t3('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/kernel_t3/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/kernel_t3/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/kernel_t3/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/kernel_t3/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/kernel_t3/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/kernel_t3/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/kernel_t3/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/kernel_t3/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/kernel_t3/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_tiled_t3_256.txt\")\n",
    "test_kernel_convolution_t3()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FFT"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def kernel_convolution_fft(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\theight, width, _ = norm_img.shape\n",
    "\tk_height, k_width = kernel.shape\n",
    "\tif k_height != k_width:\n",
    "\t\traise ValueError('Input kernel matrix must be square')\n",
    "\n",
    "\t# Compute padding size\n",
    "\tpad_size = k_height // 2\n",
    "\tpad_img = np.pad(norm_img, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='constant')\n",
    "\n",
    "\t# Get padded image dimensions\n",
    "\th_p, w_p, c_p = pad_img.shape\n",
    "\n",
    "\t# Compute full convolution size\n",
    "\tfull_h = h_p + k_height - 1\n",
    "\tfull_w = w_p + k_width - 1\n",
    "\n",
    "\t# FFT of kernel (cast to float32 and pad to full size)\n",
    "\tkernel_float32 = kernel.astype(np.float32)\n",
    "\tf_k = np.fft.fft2(kernel_float32, s=(full_h, full_w))\n",
    "\n",
    "\t# Initialize result array\n",
    "\th_out = h_p - k_height + 1\n",
    "\tw_out = w_p - k_width + 1\n",
    "\tresult = np.zeros((h_out, w_out, c_p), dtype=np.float32)\n",
    "\n",
    "\t# Compute convolution for each channel\n",
    "\tstart_row = k_height - 1\n",
    "\tend_row = start_row + h_out\n",
    "\tstart_col = k_width - 1\n",
    "\tend_col = start_col + w_out\n",
    "\n",
    "\tfor c in range(c_p):\n",
    "\t\t# Extract channel\n",
    "\t\ta_c = pad_img[:, :, c]\n",
    "\t\t# FFT of padded channel\n",
    "\t\tf_a_c = np.fft.fft2(a_c, s=(full_h, full_w))\n",
    "\t\t# Element-wise multiplication in frequency domain\n",
    "\t\tf_c_c = f_a_c * f_k\n",
    "\t\t# Inverse FFT\n",
    "\t\tc_c = np.fft.ifft2(f_c_c).real\n",
    "\t\t# Crop to valid convolution size\n",
    "\t\tconv_c = c_c[start_row:end_row, start_col:end_col]\n",
    "\t\t# Store result for this channel\n",
    "\t\tresult[:, :, c] = conv_c\n",
    "\n",
    "\t# Scale back to [0, 255], clip, and convert to uint8\n",
    "\tresult = np.clip(result * 255, 0, 255).astype(np.uint8)\n",
    "\treturn result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_fft_convolution(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = kernel_convolution_fft(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_fft_convolution():\n",
    "\tos.makedirs(\"image/fft/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_fft_convolution('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_fft_convolution('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_fft_convolution('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_fft_convolution('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_fft_convolution('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_fft_convolution('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_fft_convolution('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_fft_convolution('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_fft_convolution('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tprint(box_blur_3_img.shape)\n",
    "\tsave_img(box_blur_3_img, \"image/fft/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/fft/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/fft/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/fft/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/fft/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/fft/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/fft/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/fft/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/fft/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_fft.txt\")\n",
    "test_fft_convolution()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def kernel_convolution_fft_2(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\th, w, c = norm_img.shape\n",
    "\tif kernel.shape[0] != kernel.shape[1]:\n",
    "\t\traise ValueError('Kernel must be square')\n",
    "\n",
    "\tk = kernel.shape[0]\n",
    "\tpad = k // 2\n",
    "\tpadded = np.pad(norm_img, ((pad, pad), (pad, pad), (0, 0)), mode='constant')\n",
    "\t# print(f\"Padded shape:\\n{padded.shape}\")\n",
    "\n",
    "\t# FFT size (minimal full conv)\n",
    "\tfft_h = padded.shape[0] + k - 1\n",
    "\tfft_w = padded.shape[1] + k - 1\n",
    "\t# print(f\"fft_h, fft_w:\\n{(fft_h, fft_w)}\")\n",
    "\t# FFT of kernel once\n",
    "\tkernel_fft = np.fft.fft2(kernel.astype(np.float32), s=(fft_h, fft_w))\n",
    "\t# print(f\"Kernel fft shape:\\n{kernel_fft.shape}\")\n",
    "\tout_h = padded.shape[0] - k + 1\n",
    "\tout_w = padded.shape[1] - k + 1\n",
    "\tresult = np.empty((out_h, out_w, c), dtype=np.float32)\n",
    "\n",
    "\tr0, r1 = k - 1, k - 1 + out_h\n",
    "\tc0, c1 = k - 1, k - 1 + out_w\n",
    "\n",
    "\t# Process each channel\n",
    "\tfor i in range(c):\n",
    "\t\tchannel_fft = np.fft.fft2(padded[:, :, i], s=(fft_h, fft_w))\n",
    "\t\tconv_fft = channel_fft * kernel_fft\n",
    "\t\tconv_real = np.fft.ifft2(conv_fft).real\n",
    "\t\tresult[:, :, i] = conv_real[r0:r1, c0:c1]\n",
    "\n",
    "\t# Rescale and convert\n",
    "\treturn np.clip(result * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def benchmark_fft_convolution_2(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = kernel_convolution_fft_2(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def tmp():\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tbox_blur_3_img = benchmark_fft_convolution_2('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tprint(box_blur_3_img.shape)\n",
    "tmp()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_fft_convolution_2(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = kernel_convolution_fft_2(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_fft_convolution_2():\n",
    "\tos.makedirs(\"image/fft_2/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_fft_convolution_2('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_fft_convolution_2('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_fft_convolution_2('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_fft_convolution_2('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_fft_convolution_2('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_fft_convolution_2('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_fft_convolution_2('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_fft_convolution_2('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_fft_convolution_2('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/fft_2/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/fft_2/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/fft_2/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/fft_2/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/fft_2/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/fft_2/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/fft_2/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/fft_2/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/fft_2/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_fft_2.txt\")\n",
    "test_fft_convolution_2()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FFT3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def kernel_convolution_fft_3(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Input kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Input image must be 3D')\n",
    "\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\th, w, c = norm_img.shape\n",
    "\tif kernel.shape[0] != kernel.shape[1]:\n",
    "\t\traise ValueError('Kernel must be square')\n",
    "\n",
    "\tk = kernel.shape[0]\n",
    "\tpad = k // 2\n",
    "\tpadded = np.pad(norm_img, ((pad, pad), (pad, pad), (0, 0)), mode='constant')\n",
    "\n",
    "\t# FFT size (minimal full conv)\n",
    "\tfft_h = padded.shape[0] + k - 1\n",
    "\tfft_w = padded.shape[1] + k - 1\n",
    "\n",
    "\t# FFT of kernel once\n",
    "\tkernel_fft = np.fft.fft2(kernel.astype(np.float32), s=(fft_h, fft_w))\n",
    "\n",
    "\tout_h = padded.shape[0] - k + 1\n",
    "\tout_w = padded.shape[1] - k + 1\n",
    "\n",
    "\tr0, r1 = k - 1, k - 1 + out_h\n",
    "\tc0, c1 = k - 1, k - 1 + out_w\n",
    "\n",
    "\tpadded_transposed = np.moveaxis(padded, -1, 0)  # (c, H, W)\n",
    "\tchannel_fft = np.fft.fft2(padded_transposed, s=(fft_h, fft_w), axes=(-2, -1))  # (c, Hf, Wf)\n",
    "\tconv_fft = channel_fft * kernel_fft[None, :, :]\n",
    "\tconv_real = np.fft.ifft2(conv_fft, axes=(-2, -1)).real  # (c, Hf, Wf)\n",
    "\tresult = np.moveaxis(conv_real[:, r0:r1, c0:c1], 0, -1)  # (H, W, c)\n",
    "\treturn np.clip(result * 255.0, 0, 255).astype(np.uint8)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def benchmark_fft_convolution_3(name: str, img_2d: np.ndarray, kernel: np.ndarray):\n",
    "\ttracemalloc.start()\n",
    "\tstart_time = time.perf_counter()\n",
    "\tresult = kernel_convolution_fft_3(img_2d, kernel)\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tcurrent, peak = tracemalloc.get_traced_memory()\n",
    "\ttracemalloc.stop()\n",
    "\tprint(f\"Kernel: {name}\")\n",
    "\tprint(f\"- Execution time: {elapsed_time:.6f} seconds\")\n",
    "\tprint(f\"- Current memory usage: {current / 10**6:.2f} MB\")\n",
    "\tprint(f\"- Peak memory usage: {peak / 10**6:.2f} MB\")\n",
    "\treturn result\n",
    "\n",
    "def test_fft_convolution_3():\n",
    "\tos.makedirs(\"image/fft_3/\", exist_ok=True)\n",
    "\timg = read_img(\"cat.jpg\")\n",
    "\tstart_time = time.perf_counter()\n",
    "\n",
    "\tbox_blur_3_img = benchmark_fft_convolution_3('box_blur_3', img, MAT_BOX_BLUR_3)\n",
    "\tbox_blur_7_img = benchmark_fft_convolution_3('box_blur_7', img, MAT_BOX_BLUR_7)\n",
    "\tbox_blur_15_img = benchmark_fft_convolution_3('box_blur_15', img, MAT_BOX_BLUR_15)\n",
    "\n",
    "\tgauss_blur_3_img = benchmark_fft_convolution_3('gauss_blur_3', img, MAT_GAUSS_BLUR_3)\n",
    "\tgauss_blur_5_img = benchmark_fft_convolution_3('gauss_blur_5', img, MAT_GAUSS_BLUR_5)\n",
    "\tgauss_blur_7_img = benchmark_fft_convolution_3('gauss_blur_7', img, MAT_GAUSS_BLUR_7)\n",
    "\tgauss_blur_15_img = benchmark_fft_convolution_3('gauss_blur_15', img, MAT_GAUSS_BLUR_15)\n",
    "\tgauss_blur_21_img = benchmark_fft_convolution_3('gauss_blur_21', img, MAT_GAUSS_BLUR_21)\n",
    "\n",
    "\tunsharp_blur_img = benchmark_fft_convolution_3('unsharp_blur', img, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "\tend_time = time.perf_counter()\n",
    "\telapsed_time = end_time - start_time\n",
    "\tprint(f\"--------------- End in: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "\tsave_img(box_blur_3_img, \"image/fft_3/box_blur_3_cat.png\")\n",
    "\tsave_img(box_blur_7_img, \"image/fft_3/box_blur_7_cat.png\")\n",
    "\tsave_img(box_blur_15_img, \"image/fft_3/box_blur_15_cat.png\")\n",
    "\n",
    "\tsave_img(gauss_blur_3_img, \"image/fft_3/gauss_blur_3_cat.png\")\n",
    "\tsave_img(gauss_blur_5_img, \"image/fft_3/gauss_blur_5_cat.png\")\n",
    "\tsave_img(gauss_blur_7_img, \"image/fft_3/gauss_blur_7_cat.png\")\n",
    "\tsave_img(gauss_blur_15_img, \"image/fft_3/gauss_blur_15_cat.png\")\n",
    "\tsave_img(gauss_blur_21_img, \"image/fft_3/gauss_blur_21_cat.png\")\n",
    "\n",
    "\tsave_img(unsharp_blur_img, \"image/fft_3/unsharp_blur_cat.png\")\n",
    "file_stdout(\"output/bench_fft_3.txt\")\n",
    "test_fft_convolution_3()\n",
    "reset_stdout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def kernel_convolution_fft_4(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "\tif kernel.ndim != 2:\n",
    "\t\traise ValueError('Kernel must be 2D')\n",
    "\tif img_2d.ndim != 3:\n",
    "\t\traise ValueError('Image must be 3D (H, W, C)')\n",
    "\n",
    "\t# Normalize image\n",
    "\tnorm_img = img_2d.astype(np.float32) / 255.0\n",
    "\theight, width, channels = norm_img.shape\n",
    "\tk_height, k_width = kernel.shape\n",
    "\n",
    "\tif k_height != k_width:\n",
    "\t\traise ValueError('Kernel must be square')\n",
    "\n",
    "\tpad = k_height // 2\n",
    "\tpadded = np.pad(norm_img, ((pad, pad), (pad, pad), (0, 0)), mode='constant')\n",
    "\n",
    "\t# Compute FFT shape once\n",
    "\tfft_h = padded.shape[0] + k_height - 1\n",
    "\tfft_w = padded.shape[1] + k_width - 1\n",
    "\n",
    "\t# Precompute FFT of kernel\n",
    "\tkernel_fft = np.fft.fft2(kernel.astype(np.float32), s=(fft_h, fft_w))\n",
    "\n",
    "\t# Prepare output array\n",
    "\toutput = np.empty((height, width, channels), dtype=np.float32)\n",
    "\n",
    "\tfor c in range(channels):\n",
    "\t\t# FFT of single channel\n",
    "\t\tchannel_fft = np.fft.fft2(padded[:, :, c], s=(fft_h, fft_w))\n",
    "\t\tconv_fft = channel_fft * kernel_fft\n",
    "\t\tconv = np.fft.ifft2(conv_fft).real\n",
    "\n",
    "\t\t# Crop to original size\n",
    "\t\tstart_h = k_height - 1\n",
    "\t\tstart_w = k_width - 1\n",
    "\t\toutput[:, :, c] = conv[start_h:start_h + height, start_w:start_w + width]\n",
    "\n",
    "\treturn np.clip(output * 255, 0, 255).astype(np.uint8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def kernel_convolution_rfft(img_2d: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    if kernel.ndim != 2:\n",
    "        raise ValueError('Input kernel must be 2D')\n",
    "    if img_2d.ndim != 3:\n",
    "        raise ValueError('Input image must be 3D')\n",
    "\n",
    "    norm_img = img_2d.astype(np.float32) / 255.0\n",
    "    h, w, c = norm_img.shape\n",
    "    if kernel.shape[0] != kernel.shape[1]:\n",
    "        raise ValueError('Kernel must be square')\n",
    "\n",
    "    k = kernel.shape[0]\n",
    "    pad = k // 2\n",
    "    padded = np.pad(norm_img, ((pad, pad), (pad, pad), (0, 0)), mode='constant')\n",
    "\n",
    "    # FFT size (minimal full convolution)\n",
    "    fft_h = padded.shape[0] + k - 1\n",
    "    fft_w = padded.shape[1] + k - 1\n",
    "\n",
    "    # FFT of kernel using rfft2\n",
    "    kernel_fft = np.fft.rfft2(kernel.astype(np.float32), s=(fft_h, fft_w))\n",
    "\n",
    "    # Output size\n",
    "    out_h = padded.shape[0] - k + 1\n",
    "    out_w = padded.shape[1] - k + 1\n",
    "    result = np.empty((out_h, out_w, c), dtype=np.float32)\n",
    "\n",
    "    # Cropping indices\n",
    "    r0, r1 = k - 1, k - 1 + out_h\n",
    "    c0, c1 = k - 1, k - 1 + out_w\n",
    "\n",
    "    # Process each channel\n",
    "    for i in range(c):\n",
    "        channel_fft = np.fft.rfft2(padded[:, :, i], s=(fft_h, fft_w))\n",
    "        conv_fft = channel_fft * kernel_fft\n",
    "        conv_real = np.fft.irfft2(conv_fft, s=(fft_h, fft_w))\n",
    "        result[:, :, i] = conv_real[r0:r1, c0:c1]\n",
    "\n",
    "    # Rescale and convert\n",
    "    return np.clip(result * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def test():\n",
    "\timg = read_img('cat.jpg')\n",
    "\tout = kernel_convolution_rfft()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_2d = read_img(\"cat.jpg\")\n",
    "\n",
    "# Run multiple trials\n",
    "num_trials = 50\n",
    "v1 = []\n",
    "v2 = []\n",
    "v3 = []\n",
    "v4 = []\n",
    "\n",
    "def test_v1():\n",
    "\tkernel_convolution_fft(img_2d, MAT_BOX_BLUR_3)\n",
    "\tkernel_convolution_fft(img_2d, MAT_GAUSS_BLUR_15)\n",
    "\tkernel_convolution_fft(img_2d, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "def test_v2():\n",
    "\tkernel_convolution_fft_2(img_2d, MAT_BOX_BLUR_3)\n",
    "\tkernel_convolution_fft_2(img_2d, MAT_GAUSS_BLUR_15)\n",
    "\tkernel_convolution_fft_2(img_2d, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "def test_v3():\n",
    "\tkernel_convolution_fft_3(img_2d, MAT_BOX_BLUR_3)\n",
    "\tkernel_convolution_fft_3(img_2d, MAT_GAUSS_BLUR_15)\n",
    "\tkernel_convolution_fft_3(img_2d, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "def test_v4():\n",
    "\tkernel_convolution_rfft(img_2d, MAT_BOX_BLUR_3)\n",
    "\tkernel_convolution_rfft(img_2d, MAT_GAUSS_BLUR_15)\n",
    "\tkernel_convolution_rfft(img_2d, MAT_UNSHARP_BLUR_5)\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    # t1 = timeit.timeit(test_v1, number=1)\n",
    "    t2 = timeit.timeit(test_v2, number=1)\n",
    "    # t3 = timeit.timeit(test_v3, number=1)\n",
    "    t4 = timeit.timeit(test_v4, number=1)\n",
    "    # v1.append(t1)\n",
    "    v2.append(t2)\n",
    "    # v3.append(t3)\n",
    "    v4.append(t4)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.plot(v1, label='v1')\n",
    "plt.plot(v2, label='v2')\n",
    "# plt.plot(v3, label='v3')\n",
    "plt.plot(v4, label='v4')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Performance Comparison: FFT')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "# print(f\"Average time - v1: {np.mean(v1):.6f} sec\")\n",
    "print(f\"Average time - v2: {np.mean(v2):.6f} sec\")\n",
    "# print(f\"Average time - v3: {np.mean(v3):.6f} sec\")\n",
    "print(f\"Average time - v4: {np.mean(v4):.6f} sec\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adjust_contrast_no_percentiles(img_2d, contrast_factor=1.0):\n",
    "\timg_2d = np.clip(img_2d, 0, 255)\n",
    "\n",
    "\tnormalized = img_2d / 255.0\n",
    "\tnormalized -= 0.5\n",
    "\tnormalized *= contrast_factor\n",
    "\tnormalized += 0.5\n",
    "\n",
    "\tadjusted = np.clip(normalized, 0, 1) * 255\n",
    "\treturn adjusted.astype(np.uint8)\n",
    "\n",
    "def adjust_contrast_with_percentiles(img_2d, contrast_factor=1.0):\n",
    "\tif contrast_factor == 1.0:\n",
    "\t\treturn img_2d\n",
    "\tminval, maxval = np.percentile(img_2d, [2, 98])\n",
    "\timg_2d = np.clip(img_2d, minval, maxval)\n",
    "\tnormalized = (img_2d - minval) / (maxval - minval)\n",
    "\n",
    "\t# Adjust contrast\n",
    "\tnormalized -= 0.5\n",
    "\tnormalized *= contrast_factor\n",
    "\tnormalized += 0.5\n",
    "\t# Clip and scale back to [0, 255]\n",
    "\tadjusted = np.clip(normalized, 0, 1) * 255\n",
    "\treturn adjusted.astype(np.uint8)\n",
    "\n",
    "def contrast_method_1(image: np.ndarray, factor: float):\n",
    "    \"\"\"Adjust contrast using fixed midpoint (127.5).\"\"\"\n",
    "    mid = 127.5\n",
    "    new = (image - mid) * factor + mid\n",
    "    return np.clip(new, 0, 255).astype(np.uint8)\n",
    "\n",
    "def contrast_method_2(image: np.ndarray, factor: float):\n",
    "    \"\"\"Adjust contrast using normalized method (adaptive min/max).\"\"\"\n",
    "    min_val = image.min(axis=(0, 1), keepdims=True)\n",
    "    max_val = image.max(axis=(0, 1), keepdims=True)\n",
    "\n",
    "    norm = (image - min_val) / (max_val - min_val + 1e-8)       # Normalize to [0,1]\n",
    "    adjusted = (norm - 0.5) * factor + 0.5                      # Contrast adjust\n",
    "    rescaled = adjusted * 255                                  # Back to [0,255]\n",
    "    return np.clip(rescaled, 0, 255).astype(np.uint8)\n",
    "\n",
    "def contrast_method_3(image: np.ndarray, factor: float):\n",
    "    \"\"\"Adjust contrast using calculated midpoint (mean of pixel values).\"\"\"\n",
    "    mid = image.mean(axis=(0, 1), keepdims=True)  # Per-channel mean\n",
    "    new = (image - mid) * factor + mid\n",
    "    return np.clip(new, 0, 255).astype(np.uint8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_2d = read_img('cat.jpg')\n",
    "no_percentile_img = adjust_contrast_no_percentiles(img_2d, -2)\n",
    "percentile_img = adjust_contrast_with_percentiles(img_2d, -2)\n",
    "\n",
    "save_img(no_percentile_img, 'image/contrast/no_percentile_cat.png')\n",
    "save_img(percentile_img, 'image/contrast/percentile_cat.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Example image read function, assuming you have an 'img' array\n",
    "img_2d = read_img('cat.jpg')\n",
    "no_percentile_img = adjust_contrast_no_percentiles(img_2d, 5)\n",
    "percentile_img = adjust_contrast_with_percentiles(img_2d, 5)\n",
    "\n",
    "save_img(no_percentile_img, 'image/contrast/no_percentile_cat.png')\n",
    "save_img(percentile_img, 'image/contrast/percentile_cat.png')\n",
    "\n",
    "# Define trial counts\n",
    "num_trials = 100\n",
    "v1 = []  # adjust_contrast_no_percentiles\n",
    "v2 = []  # adjust_contrast_with_histogram\n",
    "v3 = []  # adjust_contrast_with_percentiles\n",
    "\n",
    "def test_v1():\n",
    "\tadjust_contrast_no_percentiles(img_2d, contrast_factor=5)\n",
    "\n",
    "def test_v2():\n",
    "\tadjust_contrast_with_histogram(img_2d, contrast_factor=5)\n",
    "\n",
    "def test_v3():\n",
    "\tadjust_contrast_with_percentiles(img_2d, contrast_factor=5)\n",
    "\n",
    "for _ in range(num_trials):\n",
    "\tt1 = timeit.timeit(test_v1, number=5)\n",
    "\t# t2 = timeit.timeit(test_v2, number=5)\n",
    "\tt3 = timeit.timeit(test_v3, number=5)\n",
    "\n",
    "\tv1.append(t1)\n",
    "\t# v2.append(t2)\n",
    "\tv3.append(t3)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(v1, label='No Percentiles')\n",
    "# plt.plot(v2, label='With Histogram')\n",
    "plt.plot(v3, label='With Percentiles')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Contrast Adjustment Benchmark')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Average time - No Percentiles: {np.mean(v1):.6f} sec\")\n",
    "# print(f\"Average time - With Histogram: {np.mean(v2):.6f} sec\")\n",
    "print(f\"Average time - With Percentiles: {np.mean(v3):.6f} sec\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
